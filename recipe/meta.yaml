{% set name = "libtorch" %}
{% set version = "0.5.0" %}

{% set version = "2.5.1" %}
{% set sha256 = "740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266" %}
{% set build = 0 %}

# Keep this in sync with the release
{% set smoke_test_commit = "8757658a36dfc1d7c85da543bd424ce1cc546f74" %}

# Use a higher build number for the CUDA variant, to ensure that it's
# preferred by conda's solver, and it's preferentially
# installed where the platform supports it.
{% if gpu_variant != "cpu" %}
{% set build = build + 200 %}
{% endif %}

{% if blas_impl == "mkl" %}
{% set build = build + 100 %}
{% endif %}

{% if not (gpu_variant or "").startswith("cuda") %}
{% set cuda_major = 0 %}
{% else %}
{% set cuda_major = environ.get("cuda_compiler_version", "11.8").split(".")[0] | int %}
{% endif %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  # The "pytorch-v" tarballs contain submodules; the "pytorch-" ones don't.
  url: https://github.com/pytorch/pytorch/releases/download/v{{ version }}/pytorch-v{{ version }}.tar.gz
  sha256: {{ sha256 }}
  patches:
    - patches/0001-windows-FindMKL-add-library-suffix.patch                  # [win]
    - patches/0002-swap-openmp-search-precedence.patch                       # [blas_impl == "mkl"]
    - patches/0003-Force-usage-of-python-3-and-error-without-numpy.patch
    # https://github.com/pytorch/pytorch/pull/137084
    - patches/0004-Help-find-numpy.patch
    # https://github.com/pytorch/pytorch/pull/138287
    - patches/0005-Use-system-nvtx3.patch
    # sympy 1.13.2 was reported to result in test failures on Windows and mac
    # https://github.com/pytorch/pytorch/pull/133235
    - patches/0006-Update-sympy-version.patch
    - patches/0007-continue-tests-on-failure.patch
    - patches/0008-add-missing-includes.patch

    # See https://github.com/pytorch/pytorch/pull/137331
    # for status
    - patches/137331.patch
  # url: https://raw.githubusercontent.com/pytorch/builder/{{ smoke_test_commit }}/test/smoke_test/smoke_test.py
  #   folder: smoke_test

build:
  number: {{ build }}
  string: gpu_cuda{{ cuda_compiler_version | replace('.', '') }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [gpu_variant == "cuda-12"]
  string: gpu_mps_h{{PKG_HASH}}_{{ PKG_BUILDNUM }}                                                   # [gpu_variant == "metal"]
  string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                 # [gpu_variant == "cpu"]
  detect_binary_files_with_prefix: false
  # run_exports:
  #   - {{ pin_subpackage('libtorch', max_pin='x.x') }}
  ignore_run_exports_from:
    - python *                               # [megabuild]
    - numpy *                                # [megabuild]
    - cross-python_{{ target_platform }}     # [megabuild and build_platform != target_platform]
  ignore_run_exports:
    - python *                               # [megabuild]
    - numpy *                                # [megabuild]
  skip: True  # [py<39]
  missing_dso_whitelist:
    # The are dynamically loaded from %SP_DIR%\torch\lib\
    - "**/asmjit.dll"             # [win]
    - "**/c10.dll"                # [win]
    - "**/fbgemm.dll"             # [win]
    - "**/shm.dll"                # [win]
    - "**/torch_cpu.dll"          # [win]
    - "**/torch_python.dll"       # [win]
    - $RPATH/ld64.so.1  # [s390x]

requirements:
  # Keep this list synchronized (except for python*, numpy*) in outputs
  # We use python to build libtorch as well because it is easier
  build:
    # When you change 3.12 here, change it in build.sh as well
    - python 3.12                            # [megabuild and build_platform != target_platform]
    - python                                 # [not megabuild and build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - numpy  *                               # [megabuild and build_platform != target_platform]
    - numpy                                  # [not megabuild and build_platform != target_platform]
    #- {{ stdlib('c') }}
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                 # [(gpu_variant or "").startswith("cuda")]
    - nvtx-c                                 # [cuda_compiler_version != "None" and build_platform != target_platform]
    {% if cuda_major >= 12 %}
    - cuda-driver-dev                        # [build_platform != target_platform]
    - cuda-cudart-dev                        # [build_platform != target_platform]
    - cuda-nvrtc-dev                         # [build_platform != target_platform]
    - cuda-nvtx-dev                          # [build_platform != target_platform]
    - cuda-nvml-dev                          # [build_platform != target_platform]
    - cuda-profiler-api                      # [build_platform != target_platform]
    - libcublas-dev                          # [build_platform != target_platform]
    - libcufft-dev                           # [build_platform != target_platform]
    - libcurand-dev                          # [build_platform != target_platform]
    - libcusolver-dev                        # [build_platform != target_platform]
    - libcusparse-dev                        # [build_platform != target_platform]
    {% endif %}
    # Dec 2020: it seems that git is broken on windows, so we use m2-git
    - m2-patch  # [win]
    - m2-git    # [win]
    - patch     # [not win]
    - git       # [not win]
    - libgomp        # [linux]
    # This has a strong run_export so we don't need to put it in `host` or `run`
    # We use llvm-openmp for openblas variants on osx.
    - llvm-openmp 14.0.6              # [osx and not (blas_impl == "mkl")]
    - cmake
    - ninja-base
    # Keep libprotobuf here so that a compatibile version
    # of protobuf is installed between build and host
    - libprotobuf    # [not win]
    - protobuf       # [not win]
    - make      # [linux]
    # Uncomment to use ccache, see README and build_pytorch.sh
    # - ccache
  host:
    # GPU requirements
    - cudnn 9.1.1.17                  # [(gpu_variant or "").startswith("cuda")]
    - nccl 2.21.5.1                   # [(gpu_variant or "").startswith("cuda")]
    - magma 2.7.1                     # [(gpu_variant or "").startswith("cuda")]
    - cuda-version {{ cuda_compiler_version }}  # [(gpu_variant or "").startswith("cuda")]
    - nvtx-c                          # [(gpu_variant or "").startswith("cuda")]
    {% if cuda_major >= 12 %}
    - cuda-driver-dev
    - cuda-cudart-dev
    - cuda-nvrtc-dev
    - cuda-nvtx-dev
    - cuda-nvml-dev
    - cuda-profiler-api
    - libcublas-dev
    - libcufft-dev
    - libcurand-dev
    - libcusolver-dev
    - libcusparse-dev
    - cuda-cupti
    {% endif %}
    # other requirements
    - python 3.12  # [megabuild]
    - python       # [not megabuild]
    - numpy 2.*
    - pip
    - setuptools <=72.1.0
    - wheel
    - pyyaml
    - requests
    - future
    - six
    - mkl-devel {{ mkl }}.*           # [blas_impl == "mkl"]
    - openblas-devel {{ openblas }}   # [blas_impl == "openblas"]
    # - libcblas * *_mkl      # [blas_impl == "mkl"]
    # - libcblas              # [blas_impl != "mkl"]
    # - liblapack             # [blas_impl != "mkl"]
    # - libgomp   # [linux]
    # We pull in the same versions of mkl and intel-openmp: intel aligns the versions
    # We use intel-openmp for all mkl variants.
    # For openblas on win and linux, we don't specify any openmp implementation; it comes from the compiler.
    - intel-openmp   {{ mkl }}        # [blas_impl == "mkl"]
    - llvm-openmp 14.0.6              # [osx and not (blas_impl == "mkl")]
    - libabseil
    - libprotobuf {{ libprotobuf }}   # [not win]
    - sleef 3.5.1                     # [not win]
    - typing
    - libuv
    - pkg-config  # [unix]
    - typing_extensions
    - pybind11 2.12.1
    - eigen 3.3.7
    - astunparse 1.6.3
    - opentelemetry-api
  # satisfy overlinking checks
  run:
    - {{ pin_compatible('intel-openmp') }}   # [blas_impl == "mkl"]

test:
  commands:
    # libraries
    {% for each_lib in [ 'libc10', 'libshm', 'libtorch', 'libtorch_cpu', 'libtorch_global_deps'] %}
    - test -f $PREFIX/lib/{{ each_lib }}.so     # [linux]
    - test -f $PREFIX/lib/{{ each_lib }}.dylib  # [osx]
    {% endfor %}
    {% for each_lib in ['libc10_cuda', 'libcaffe2_nvrtc', 'libtorch_cuda', 'libtorch_cuda_linalg'] %}
    - test -f $PREFIX/lib/{{ each_lib }}.so     # [linux and (gpu_variant or "").startswith("cuda")]
    {% endfor %}

about:
  home: https://pytorch.org/
  dev_url: https://github.com/pytorch/pytorch
  license: BSD-3-Clause
  license_family: BSD
  license_file:
    - LICENSE
    - NOTICE
    - third_party/pybind11/LICENSE
  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.
  description: |
    PyTorch is a Python package that provides two high-level features:
      - Tensor computation (like NumPy) with strong GPU acceleration
      - Deep neural networks built on a tape-based autograd system
    You can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.
  doc_url: https://pytorch.org/docs/

extra:
  skip-lints:
    - missing_tests